# -*- coding: utf-8 -*-
"""Data_Collection_Foursquare_API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sLaySBrcAV9E7S8Hk4_sWwK00dosr_Oz
"""

import pandas as pd
import numpy as np
import requests 
import re
import time
import folium

from bs4 import BeautifulSoup
from geopy.geocoders import Nominatim

"""### Web Scraping for London Neighborhoods"""

response = requests.get("https://en.wikipedia.org/wiki/List_of_areas_of_London#List_of_districts_and_neighbourhoods_of_London")

soup = BeautifulSoup(response.text, 'html.parser')

london_table = soup.find("table", {"class": "wikitable"})

london_df = pd.read_html(str(london_table))
london_df = pd.DataFrame(london_df[0])

london_df.head()

london_df.columns.tolist()

london_df.rename(columns={"Location": "location", 
                          "London\xa0borough": "borough", 
                          "Post town": "town", 
                          "Postcode\xa0district": "post_code"}, 
                 inplace=True)

city_df = london_df[london_df["town"] == "LONDON"]

city_df = city_df.drop(columns=["Dial\xa0code", "OS grid ref"])

city_df.head()

city_df["location"].unique()

city_df[city_df["location"] == "Bromley (also Bromley-by-Bow)"] = "Bromley"

city_df[city_df["location"] == "Marylebone (also St Marylebone)"] = "Marylebone"

city_df[city_df["location"] == "Sydenham (also Lower Sydenham, Upper Sydenham)"] = "Sydenham"

def get_neighborhood_list():
  neighborhood_list = []
  for neighborhood in city_df["location"]:
      if neighborhood in neighborhood_list:
        continue
      else:
        neighborhood_list.append(neighborhood)
  return neighborhood_list

london_neighborhoods = get_neighborhood_list()

geolocator = Nominatim(user_agent="women_safety")

def get_geocodes(neighborhood_list):
  coordinates_dict = {}
  for neighborhood in neighborhood_list:
    location = geolocator.geocode(f"{neighborhood}, London")
    if hasattr(location, "latitude"):
      coordinates_dict[neighborhood] = f"{location.latitude},{location.longitude}"
    else:
      coordinates_dict[neighborhood] = None
  return coordinates_dict

coordinates = get_geocodes(london_neighborhoods)

del coordinates["Somerstown"]

"""### Collecting pubs data from Foursquare API"""

coordinates

category = "13018"

category = "19046,12072"

def make_request(url):
  headers = {
      "Accept": "application/json",
      "Authorization": "fsq3KLJFjwCDD7cR7rlcFv3C1796jGtkKOz+QN0XeF0AcL4="
  }
  response = requests.request("GET", url, headers=headers)
  return response

def get_next_url(response):
  try:
    return re.findall("<(.*?)>", response.headers["Link"])[0]
  except (KeyError, IndexError):
    return None

def get_nearby_venues_data(coordinate):
  json_list = []
  url = f"https://api.foursquare.com/v3/places/search?ll={coordinate}&radius=500&categories={category}&fields=fsq_id%2Cname%2Cgeocodes%2Clocation%2Ccategories&limit=50"

  while url != None:
    response = make_request(url)
    json_file = response.json()
    json_list.append(json_file)
    
    url = get_next_url(response)
    time.sleep(0.1)
    print(url)
    print(response.headers)

  return json_list

def get_venues_data():
  venues_data = []
  for coordinate in coordinates.values():
    nearby_venues = get_nearby_venues_data(coordinate)
    venues_data.extend(nearby_venues)
  return venues_data

venues_data = get_venues_data()

len(venues_data)

def parse_json_list():
  list_venues = []
  for json in venues_data[1:]:
    if "results" in json:
      list_venues.extend(json["results"])
    else:
      continue
  return list_venues

list_venues = parse_json_list()

len(list_venues)

df = pd.DataFrame(list_venues)

df

df.fsq_id.duplicated().value_counts()

df.to_csv("city_of_london_pubs.csv")

"""### Collecting Subway and Police Data from Foursquare API"""

venues_data = get_venues_data()

len(venues_data)

venues_data

police_metro_json = parse_json_list()

len(police_metro_json)

df2 = pd.DataFrame(police_metro_json)

df2.head()

df2.fsq_id.duplicated().value_counts()

df2.to_csv("city_of_london_metro_police.csv")

"""### Place Details from Foursquare API"""

id_list = []
for id in df.fsq_id:
  id_list.append(id)

id_list

json_list = []
for id in df.fsq_id:
  url = f"https://api.foursquare.com/v3/places/{id}?fields=fsq_id%2Crating%2Cpopularity%2Cprice"

  headers = {
      "Accept": "application/json",
      "Authorization": "fsq3KLJFjwCDD7cR7rlcFv3C1796jGtkKOz+QN0XeF0AcL4="
  }

  response = requests.request("GET", url, headers=headers)
  json_file = response.json()
  json_list.append(json_file)
  print(response.text)

len(json_list)

list_of_venues = []
for json in json_list:
  list_of_venues.append(json)

list_of_venues

df3 = pd.DataFrame(list_of_venues)

df3.head()

df3.to_csv("pubs_rich_data.csv")

